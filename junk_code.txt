                # model_flight_image = ((model_flight_image.astype(float)*3 + arena_fresh.astype(float)*1 ) / 4).astype(np.uint8)
                # session_trials_plot = ((session_trials_plot.astype(float) * 1 + initial_session_trials_plot.astype(float) * 1) / 2).astype(np.uint8)   

             # cv2.circle(session_trials_plot_background, tuple(coordinates['nose'][:,frame_num-1].astype(np.uint16)), 2, (0,0,0), -1)
                # cv2.circle(session_trials_plot_background, tuple(coordinates['L eye'][:, frame_num - 1].astype(np.uint16)), 2, (0,0,0), -1)
                # cv2.circle(session_trials_plot_background, tuple(coordinates['R eye'][:, frame_num - 1].astype(np.uint16)), 2, (0,0,0), -1)
                # cv2.circle(session_trials_plot_background, tuple(coordinates['L ear'][:, frame_num - 1].astype(np.uint16)), 2, (0,0,0), -1)
                # cv2.circle(session_trials_plot_background, tuple(coordinates['neck'][:, frame_num - 1].astype(np.uint16)), 2, (0,0,0), -1)
                # cv2.circle(session_trials_plot_background, tuple(coordinates['R ear'][:, frame_num - 1].astype(np.uint16)), 2, (0,0,0), -1)


# if vid_num:
#     if not 'Arena Transformation 2' in self.session['Metadata'].videodata[0]:
#         self.session['Metadata'].videodata[0]['Arena Transformation 2'] = []
#         self.session['Metadata'].videodata[0]['Arena Transformation 2'] = register_arena(
#          self.session['Metadata'].videodata[0]['Background'], fisheye_map_location, self.x_offset, self.y_offset, self.obstacle_type)
#     self.registration = self.session['Metadata'].videodata[0]['Arena Transformation 2']
# if not vid_num:
#   self.videoname = '{}_{}_{}-{} ({}\')'.format(self.session['Metadata'].experiment,
#                                                                      self.session['Metadata'].mouse_id,
#                                                                      stim_type, trial_num + 1 + vid_1_trials, round((stim_frame + vid_1_frames) / self.fps / 60))
#
# vid_1_frames = end_frame
# vid_1_trials = trial_num



# def find_raw_video(video_path):
#     vid = cv2.VideoCapture(video_path)
#     ret, frame = vid.read()
#     vid.release()
#     print(colored('Tracking the whole session from ' + video_path, 'green'))
#
#     return video_path, frame

    # video_clip_EXPLORE = cv2.VideoWriter(os.path.join(savepath, videoname + '_EXPLORE.avi'), fourcc,
    #                                  200, (width, height), True)
    # in_color = np.array([122, 222, 122])
    # out_color = np.array([122, 122, 222])

    # explore_in_color = 1 - ( 1 - in_color / [255, 255, 255] ) / ( np.mean( 1 - in_color / [255, 255, 255] ) / .08)
    # explore_out_color = 1 - ( 1 - out_color / [255, 255, 255] ) / ( np.mean( 1 - out_color / [255, 255, 255] ) / .08)

# AWAY FROM SHELTER
# if speed_toward_shelter > 0:
#     fast_color = np.array([152, 152, 222]) # red
#     slow_color = np.array([155, 225, 245]) # brown-yellow
#     slow_color = np.array([224, 245, 245])  # gray yellow
#     multiplier = .02
#     if speed > 10:
#         speed_color = fast_color
#     else:
#         speed_color = (speed * fast_color + (10 - speed) * slow_color) / 10
#
#     speed_color = 1 - (1 - speed_color / [255, 255, 255]) / (np.mean(1 - speed_color / [255, 255, 255]) / (.1 * speed * multiplier))
#
#     exploration_arena_both[model_mouse_mask.astype(bool)] = exploration_arena_both[model_mouse_mask.astype(bool)] * speed_color

########################################################################################################################


# # =================================================================================
# #              GENERATE PERI-STIMULUS VIDEO CLIPS and FLIGHT IMAGE
# # =================================================================================
# def peri_stimulus_video_clip(vidpath = '', videoname = '', savepath = '', start_frame=0., end_frame=100., stim_frame = 0,
#                    registration = 0, fps=False, save_clip = False, display_clip = False, counter = True, make_flight_image = True):
#     # GET BEAHVIOUR VIDEO - ######################################
#     vid = cv2.VideoCapture(vidpath)
#     if not fps: fps = vid.get(cv2.CAP_PROP_FPS)
#     width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))
#     height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
#
#     # SETUP VIDEO CLIP SAVING - ######################################
#     # file_already_exists = os.path.isfile(os.path.join(savepath,videoname+'.avi'))
#     fourcc = cv2.VideoWriter_fourcc(*"XVID")  # LJPG for lossless, XVID for compressed
#     border_size = 20
#     if save_clip:
#         if not os.path.isdir(savepath):
#             os.makedirs(savepath)
#         video_clip = cv2.VideoWriter(os.path.join(savepath,videoname+'.avi'), fourcc, fps, (width+2*border_size*counter, height+2*border_size*counter), counter)
#     vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
#
#     pre_stim_color = [255, 120, 120]
#     post_stim_color = [120, 120, 255]
#
#     if registration[3]: # setup fisheye correction
#         maps = np.load(registration[3])
#         map1 = maps[:, :, 0:2]
#         map2 = maps[:, :, 2] * 0
#     else:
#         print(colored('Fisheye correction unavailable', 'green'))
#     # RUN SAVING AND ANALYSIS OVER EACH FRAME - ######################################
#     while True: #and not file_already_exists:
#         ret, frame = vid.read()  # get the frame
#         if ret:
#             frame_num = vid.get(cv2.CAP_PROP_POS_FRAMES)
#             if [registration]:
#                 # load the fisheye correction
#                 frame_register = frame[:, :, 0]
#                 if registration[3]:
#                     frame_register = cv2.copyMakeBorder(frame_register, y_offset, int((map1.shape[0] - frame.shape[0]) - y_offset),
#                                                         x_offset, int((map1.shape[1] - frame.shape[1]) - x_offset), cv2.BORDER_CONSTANT, value=0)
#                     frame_register = cv2.remap(frame_register, map1, map2, interpolation=cv2.INTER_LINEAR,
#                                                 borderMode=cv2.BORDER_CONSTANT, borderValue=0)
#                     frame_register = frame_register[y_offset:-int((map1.shape[0] - frame.shape[0]) - y_offset),
#                                      x_offset:-int((map1.shape[1] - frame.shape[1]) - x_offset)]
#                 frame = cv2.cvtColor(cv2.warpAffine(frame_register, registration[0], frame.shape[0:2]),cv2.COLOR_GRAY2RGB)
#
#             # MAKE ESCAPE TRAJECTORY IMAGE - #######################################
#             if make_flight_image:
#                 # at stimulus onset, take this frame to lay all the superimposed mice on top of
#                 if frame_num == stim_frame:
#                     flight_image_by_distance = frame[:,:,0].copy()
#
#                 # in subsequent frames, see if frame is different enough from previous image to merit joining the image
#                 elif frame_num > stim_frame and (frame_num - stim_frame) < 30*10:
#                     # get the number of pixels that are darker than the flight image
#                     difference_from_previous_image = ((frame[:,:,0]+.001) / (flight_image_by_distance+.001))<.55 #.5 original parameter
#                     number_of_darker_pixels = np.sum(difference_from_previous_image)
#
#                     # if that number is high enough, add mouse to image
#                     if number_of_darker_pixels > 1050: # 850 original parameter
#                         # add mouse where pixels are darker
#                         flight_image_by_distance[difference_from_previous_image] = frame[difference_from_previous_image,0]
#
#             # SHOW BOUNDARY AND TIME COUNTER - #######################################
#             if counter and (display_clip or save_clip):
#                 # cv2.rectangle(frame, (0, height), (150, height - 60), (150,150,150), -1)
#                 if frame_num < stim_frame:
#                     cur_color = tuple([x * ((frame_num - start_frame) / (stim_frame - start_frame)) for x in pre_stim_color])
#                     sign = ''
#                 else:
#                     cur_color = tuple([x * (1 - (frame_num - stim_frame) / (end_frame-stim_frame))  for x in post_stim_color])
#                     sign = '+'
#
#                 # border and colored rectangle around frame
#                 frame = cv2.copyMakeBorder(frame, border_size, border_size, border_size, border_size,cv2.BORDER_CONSTANT, value=cur_color)
#
#                 # report video details
#                 cv2.putText(frame, videoname, (20, 40), 0, .55, (180, 180, 180), thickness=1)
#
#                 # report time relative to stimulus onset
#                 frame_time = (frame_num - stim_frame) / fps
#                 frame_time = str(round(.1*round(frame_time/.1), 1))+ '0'*(abs(frame_time)<10)
#                 cv2.putText(frame, sign + str(frame_time) + 's', (width-110, height+10), 0, 1,(180,180,180), thickness=2)
#
#             else:
#                 frame = frame[:,:,0] # or use 2D grayscale image instead
#
#             # SHOW AND SAVE FRAME - #######################################
#             if display_clip:
#                 cv2.imshow('Trial Clip', frame)
#             if save_clip:
#                 video_clip.write(frame)
#             if display_clip:
#                 if cv2.waitKey(1) & 0xFF == ord('q'):
#                     break
#             if frame_num >= end_frame:
#                 break
#         else:
#             print('Problem with movie playback')
#             cv2.waitKey(1000)
#             break
#
#     # wrap up
#     vid.release()
#     if make_flight_image:
#         flight_image_by_distance = cv2.copyMakeBorder(flight_image_by_distance, border_size, border_size, border_size, border_size, cv2.BORDER_CONSTANT, value=0)
#         cv2.putText(flight_image_by_distance, videoname, (border_size, border_size-5), 0, .55, (180, 180, 180), thickness=1)
#         cv2.imshow('Flight image', flight_image_by_distance)
#         cv2.waitKey(10)
#         scipy.misc.imsave(os.path.join(savepath, videoname + '.tif'), flight_image_by_distance)
#     if save_clip:
#         video_clip.release()
#     # cv2.destroyAllWindows()
#
