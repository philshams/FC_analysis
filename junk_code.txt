                    # # analyze planning points
                    # if analysis_options['planning']:
                    #     try: planning_arena
                    #     except: planning_arena = np.ones(homing_arena.shape) * 255
                    #     planning_arena = planning(planning_arena, session_trials_plot_background, border_size, self.coordinates,
                    #                                        previous_stim_frame, stim_frame, self.videoname, save_folder, trial_groups, group_idx,
                    #                                          trial_types[trials_completed], self.obstacle_type, self.subgoal_location)
                    #
                    # # analyze sub-goals
                    # if analysis_options['target repetition']:
                    #     try: target_arena
                    #     except: target_arena = np.ones(homing_arena.shape) * 255
                    #     target_arena = target_practice(target_arena, session_trials_plot_background, border_size, self.coordinates,
                    #                                        previous_stim_frame, stim_frame, trial_groups, distance_from_start, self.videoname, save_folder,
                    #                                         trial_types[trials_completed], self.obstacle_type, self.subgoal_location)
                    #
                    # # analyze infomark
                    # if analysis_options['infomark']:
                    #     try: infomark_mask
                    #     except: infomark_mask = np.ones(self.arena.shape[0:2]) * 255
                    #     infomark_mask = infomark(session_trials_plot_background, infomark_mask, border_size, self.coordinates, self.infomark_location,
                    #              previous_stim_frame, stim_frame, self.videoname, save_folder, self.arena)


def planning(exploration_arena_copy, session_trials_plot_background, border_size, coordinates, previous_stim_frame, stim_frame, videoname, savepath, trial_groups, group_idx, trial_type, obstacle_type, subgoal_locations):
    '''
    compute and display EXPLORATION
    go through each frame, adding the mouse silhouette
    '''

    # visualize results
    cv2.namedWindow(savepath + ' planning')

    # initialize the arena and mouse mask
    exploration_arena = copy.deepcopy(exploration_arena_copy)
    save_exploration_arena = exploration_arena.copy()
    model_mouse_mask_initial = exploration_arena[:, :, 0] * 0
    stimulus_started = True

    # instead of speed to shelter, take max of speed to shelter and speed to subgoals
    skip_frames = 300
    if previous_stim_frame == 0: previous_stim_frame -= skip_frames

    # set what this mouse considers a high speed
    speeds = [.5, 1, 4]
    high_speed, medium_speed, low_speed = speeds[2], speeds[1], speeds[0]

    # create local variables for the current epoch
    goal_speeds, _, body_angles, subgoal_angles, angular_speed, distance_from_shelter, _, _, x_location_butt, y_location_butt, x_location_face, y_location_face = \
        create_local_variables(coordinates, stim_frame, previous_stim_frame, skip_frames)

    # do convolutions to get current, future, far future, and past speeds w.r.t the shelter
    # now_speed = convolve(goal_speeds, 12, -1, time='current')  # 12?
    # past_speed = convolve(goal_speeds, 30, -1, time='past')  # 12?
    # present_angular_speed = convolve(abs(angular_speed), 8, +1, time='current')  # 12?

    # get the frame numbers to analyze
    frame_nums = np.arange(previous_stim_frame + skip_frames, stim_frame + skip_frames)

    # take homings from spontaneous homings function output
    thresholds_passed = trial_groups.copy()
    homing_record = group_idx.copy()

    # take only the bouts that end up in the shelter
    thresholds_passed_idx = np.where(homing_record)[0]

    # take only ultimate-phase homings that end in the shelter
    for i, homing_attempt in enumerate(thresholds_passed_idx):
        # if the homing attempt doesn't end up by the shelter, remove it
        if abs(homing_record[homing_attempt]) > 150:
            homing_record[homing_attempt] = 0
        # if the next homing attempt is a phase of this one, remove it
        if i < len(thresholds_passed_idx)-1:
            if homing_record[thresholds_passed_idx[i+1]] < 0:
                homing_record[homing_attempt] = 0

    # get indices
    thresholds_passed_idx = np.where(homing_record)[0]

    # loop over each start frame that passed the threshold
    for homing_num, start_idx in enumerate(thresholds_passed_idx):

        # get the frame number when the homing starts
        start_frame_num = frame_nums[start_idx]

        # initialize mouse mask
        previous_mouse_mask = model_mouse_mask_initial.copy()

        for b in range(-10, 5):

            # get the frame number to draw
            frame_num = start_frame_num + b;

            # extract DLC coordinates from the saved coordinates dictionary
            body_angle = coordinates['body_angle'][frame_num]
            body_location = tuple(coordinates['center_body_location'][:, frame_num].astype(np.uint16))

            # draw ellipses representing model mouse
            back_butt_dist = 25
            model_mouse_mask = cv2.ellipse(model_mouse_mask_initial.copy(), body_location, (int(back_butt_dist), int(back_butt_dist*.6)), 180 - body_angle, 0, 360, 1, thickness=-1)

            # if it overlaps with previous mouse mask, don't draw it
            if np.sum(model_mouse_mask * previous_mouse_mask) > (np.pi * back_butt_dist**2 /2):
                continue
            else:
                previous_mouse_mask = model_mouse_mask

            # determine color
            multiplier = 8
            speed_color = np.array([210, 242, 95])  # turquoise
            if frame_num >= stim_frame - 60:
                save_speed_color = np.array([200, 200, 240])  # red
                multiplier = 4
            else:
                save_speed_color = speed_color

            # create color multiplier to modify image
            color_multiplier = 1 - (1 - speed_color / [255, 255, 255]) / (np.mean(1 - speed_color / [255, 255, 255]) * multiplier)
            save_color_multiplier = 1 - (1 - save_speed_color / [255, 255, 255]) / (np.mean(1 - save_speed_color / [255, 255, 255]) * multiplier)

            # apply color to arena image
            exploration_arena[model_mouse_mask.astype(bool)] = exploration_arena[model_mouse_mask.astype(bool)] * color_multiplier
            save_exploration_arena[model_mouse_mask.astype(bool)] = save_exploration_arena[model_mouse_mask.astype(bool)] * save_color_multiplier

            # display image
            cv2.imshow(savepath +' planning', save_exploration_arena)

            # press q to quit
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    # blur the image
    exploration_arena_blur = cv2.GaussianBlur(save_exploration_arena, ksize=(25, 25), sigmaX=6, sigmaY=6).astype(np.uint8)
    blur_mask = cv2.cvtColor(exploration_arena_blur, cv2.COLOR_BGR2GRAY)

    # draw arena
    arena, _, _ = model_arena(exploration_arena.shape[0:2], trial_type, False, obstacle_type)
    color_arena = cv2.cvtColor(arena, cv2.COLOR_GRAY2RGB)

    # put planning points into arena
    planning_arena = color_arena.copy()
    planning_arena[blur_mask < 255] = exploration_arena_blur[blur_mask < 255]
    planning_arena[arena < 255] = color_arena[arena < 255]

    # show and save image
    cv2.imshow(savepath + ' planning', planning_arena); cv2.waitKey(1)
    session_trials_plot_background[border_size:, 0:-border_size] = planning_arena
    scipy.misc.imsave(os.path.join(savepath, videoname + '_planning.tif'), cv2.cvtColor(session_trials_plot_background, cv2.COLOR_BGR2RGB))



    return exploration_arena




def target_practice(exploration_arena_copy, session_trials_plot_background, border_size, coordinates, previous_stim_frame, stim_frame, trial_groups, distance_from_start, videoname, savepath, trial_type, obstacle_type, subgoal_locations):
    '''
    compute and display TARGET PRACTICE
    go through each locomotor bout, adding the mouse endpoint
    '''

    # visualize results
    cv2.namedWindow(savepath + ' targets')

    # initialize the arena and mouse mask
    exploration_arena = copy.deepcopy(exploration_arena_copy)
    save_exploration_arena = exploration_arena.copy()
    model_mouse_mask_initial = exploration_arena[:, :, 0] * 0
    stimulus_started = True

    # instead of speed to shelter, take max of speed to shelter and speed to subgoals
    skip_frames = 300
    if previous_stim_frame == 0: previous_stim_frame -= skip_frames

    # set what this mouse considers a high speed
    speeds = [.5, 1, 4]
    high_speed, medium_speed, low_speed = speeds[2], speeds[1], speeds[0]

    # create local variables for the current epoch
    goal_speeds, _, body_angles, subgoal_angles, angular_speed, distance_from_shelter, _, _, x_location_butt, y_location_butt, x_location_face, y_location_face = \
        create_local_variables(coordinates, stim_frame, previous_stim_frame, skip_frames)

    # do convolutions to get current, future, far future, and past speeds w.r.t the shelter
    # now_speed = convolve(goal_speeds, 12, -1, time='current')  # 12?
    # past_speed = convolve(goal_speeds, 30, -1, time='past')  # 12?
    # present_angular_speed = convolve(abs(angular_speed), 8, +1, time='current')  # 12?

    # get the frame numbers to analyze
    frame_nums = np.arange(previous_stim_frame + skip_frames, stim_frame + skip_frames)

    # take homings from spontaneous homings function output
    thresholds_passed = trial_groups.copy()

    # get points within the obstacle bound
    within_obstacle_bound = coordinates['in_fomark_bound'][previous_stim_frame+skip_frames:stim_frame+skip_frames]
    beyond_obstacle_bound = coordinates['in_subgoal_bound'][previous_stim_frame+skip_frames:stim_frame+skip_frames]

    # get the index when adequately long locomotor bouts pass the threshold
    thresholds_passed = thresholds_passed * within_obstacle_bound * beyond_obstacle_bound * (distance_from_start > 30)
    thresholds_passed_idx = np.where(thresholds_passed)[0]

    # thresholds_passed_idx = np.where(thresholds_passed * within_obstacle_bound * (head_direction < 180 )
    #                                  * (coordinates['speed_toward_subgoal'] < -low_speed) * (distance_from_start > 200) )[0]

    # initialize mouse mask
    previous_mouse_mask = model_mouse_mask_initial.copy()
    new_homing = np.concatenate((np.ones(1), np.diff(thresholds_passed_idx) > 100))

    # loop over each frame that passed the threshold
    for i, idx in enumerate(thresholds_passed_idx):

        # get frame number
        frame_num = frame_nums[idx]

        # fade away shading as homing goes on
        if new_homing[i]: time_since_start = 0

        # extract DLC coordinates from the saved coordinates dictionary
        body_angle = coordinates['body_angle'][frame_num]
        body_location = tuple(coordinates['front_location'][:, frame_num].astype(np.uint16))

        # set scale for size of model mouse
        back_butt_dist = 15

        # draw ellipses representing model mouse
        model_mouse_mask = cv2.ellipse(model_mouse_mask_initial.copy(), body_location, (int(back_butt_dist), int(back_butt_dist)), 180 - body_angle, 0, 360, 1, thickness=-1)

        # if it overlaps with previous mouse mask, don't draw it
        if np.sum(model_mouse_mask * previous_mouse_mask) > (np.pi * back_butt_dist ** 2 / 3):
            continue
        else:
            previous_mouse_mask = model_mouse_mask

        # determine color
        multiplier = 3
        speed_color = np.array([210, 242, 95])  # turquoise
        if frame_num >= stim_frame - 60:
            save_speed_color = np.array([200, 200, 240])  # red
        else:
            save_speed_color = speed_color

        multiplier = multiplier + 2*time_since_start*(frame_num < stim_frame) + .5*time_since_start*(frame_num > stim_frame)

        # create color multiplier to modify image
        color_multiplier = 1 - (1 - speed_color / [255, 255, 255]) / (np.mean(1 - speed_color / [255, 255, 255]) * multiplier)
        save_color_multiplier = 1 - (1 - save_speed_color / [255, 255, 255]) / (np.mean(1 - save_speed_color / [255, 255, 255]) * multiplier)

        # apply color to arena image
        exploration_arena[model_mouse_mask.astype(bool)] = exploration_arena[model_mouse_mask.astype(bool)] * color_multiplier
        save_exploration_arena[model_mouse_mask.astype(bool)] = save_exploration_arena[model_mouse_mask.astype(bool)] * save_color_multiplier

        # display image
        cv2.imshow(savepath +' targets', save_exploration_arena)

        # move timer
        time_since_start += 1

        # press q to quit
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break


def infomark(session_trials_plot_background, infomark_mask, border_size, coordinates, infomark_location, previous_stim_frame, stim_frame, videoname, savepath, arena):
    '''
    Determine locations that could serve as infomark
    '''

    # extract head coordinates
    x_location = coordinates['head_location'][0][previous_stim_frame:stim_frame].astype(np.uint16)
    y_location = coordinates['head_location'][1][previous_stim_frame:stim_frame].astype(np.uint16)

    # get contours for infomark
    infomark_bound = [(int(x * arena.shape[1] / 1000), int(y * arena.shape[0] / 1000)) for x, y in infomark_location]

    # only include points proximal to the obstacle
    face_dist = 30
    polygon_mask = np.zeros(arena.shape[0:2])
    cv2.drawContours(polygon_mask, [np.array(infomark_bound)], 0, 100, -1)
    polygon_mask = polygon_mask.astype(bool)

    # if the entire object has been sensed, skip calculation
    if not np.sum(polygon_mask * (arena < 255)) == np.sum(polygon_mask * (arena < 255) * (infomark_mask < 255)):

        # compute valid locations to go to subgoal
        within_obstacle_bound = []
        for i, (x, y) in enumerate(zip(x_location, y_location)):
            try:
                if polygon_mask[y, x]:
                    infomark_mask = cv2.circle(infomark_mask , (x_location[i], y_location[i]), face_dist, 0, thickness=-1)
                    cv2.imshow('infomark', infomark_mask); cv2.waitKey(1)
            # if mouse leaning across edge of frame
            except:
                pass

    # show infomark locations in red
    infomark_color = [0, 0, 255]
    infomark_arena = cv2.cvtColor(arena.copy(), cv2.COLOR_GRAY2RGB)
    infomark_arena[ polygon_mask * (arena < 255) * (infomark_mask < 255) ] = infomark_color

    cv2.imshow('infomark', infomark_arena)
    cv2.waitKey(1)

    # save colorized arena
    session_trials_plot_background[border_size:, 0:-border_size] = infomark_arena
    scipy.misc.imsave(os.path.join(savepath, videoname + '_infomark.tif'), cv2.cvtColor(session_trials_plot_background, cv2.COLOR_BGR2RGB))

    return infomark_mask

    # blur the image
    exploration_arena_blur = cv2.GaussianBlur(save_exploration_arena, ksize=(25, 25), sigmaX=6, sigmaY=6).astype(np.uint8)
    blur_mask = cv2.cvtColor(exploration_arena_blur, cv2.COLOR_BGR2GRAY)

    # draw arena
    arena, _, _ = model_arena(exploration_arena.shape[0:2], trial_type, False, obstacle_type)
    color_arena = cv2.cvtColor(arena, cv2.COLOR_GRAY2RGB)

    # put planning points into arena
    target_arena = color_arena.copy()
    target_arena[blur_mask < 255] = exploration_arena_blur[blur_mask < 255]
    target_arena[arena < 255] = color_arena[arena < 255]

    # show and save image
    cv2.imshow(savepath + ' targets', target_arena); cv2.waitKey(1)
    session_trials_plot_background[border_size:, 0:-border_size] = target_arena
    scipy.misc.imsave(os.path.join(savepath, videoname + '_targets.tif'), cv2.cvtColor(session_trials_plot_background, cv2.COLOR_BGR2RGB))



    return exploration_arena


    # # add in the stimulus response, if it's not already in there
    # distance_traveled = np.sqrt((x_location[stim_frame - previous_stim_frame - skip_frames:stim_frame - previous_stim_frame - skip_frames + 300] - x_location[stim_frame - previous_stim_frame - skip_frames]) ** 2
    #                             + (y_location[stim_frame - previous_stim_frame - skip_frames:stim_frame - previous_stim_frame - skip_frames + 300] - y_location[stim_frame - previous_stim_frame - skip_frames]) ** 2)
    # traveled_10_cm = np.where( distance_traveled > 80 )[0][0]
    # if not sum(thresholds_passed[stim_frame - previous_stim_frame - skip_frames: stim_frame - previous_stim_frame - skip_frames + traveled_10_cm]):
    #     vectors.append([(x_location[stim_frame - previous_stim_frame - skip_frames], y_location[stim_frame - previous_stim_frame - skip_frames]),
    #                   ((x_location[stim_frame - previous_stim_frame - skip_frames + traveled_10_cm], y_location[stim_frame - previous_stim_frame - skip_frames + traveled_10_cm]))])
    #     start_mouse[stim_frame - previous_stim_frame - skip_frames] = True
    #     thresholds_passed[stim_frame - previous_stim_frame - skip_frames: stim_frame - previous_stim_frame - skip_frames + traveled_10_cm] = True


###CRAZY HOMINGS

def spontaneous_homings(exploration_arena_copy, session_trials_plot_background, border_size, coordinates, previous_stim_frame, stim_frame, videoname, savepath, subgoal_locations):
    '''
    compute and display EXPLORATION
    go through each frame, adding the mouse silhouette
    '''

    # visualize results
    cv2.namedWindow(savepath +'homings'); cv2.moveWindow(savepath +'homings', 100, 50)

    # initialize arrays
    exploration_arena, save_exploration_arena, model_mouse_mask_initial, thresholds_passed, stimulus_contour_retrieved = \
        initialize_arrays(exploration_arena_copy, stim_frame, previous_stim_frame)

    # how many frames after each stimulus to look at
    skip_frames = 300

    # get the frame numbers to analyze
    frame_nums = np.arange(previous_stim_frame + skip_frames, stim_frame + skip_frames)

    # set the speed parameters
    speeds = [[.5, .75, 1],[.5, 1, 4]] # speeds = [.5, 1, 2, 4]
    speed_colors = [np.array([180, 210, 250]), np.array([220, 230, 205])]
    speed_colors = [np.array([190, 230, 254]), np.array([220, 254, 220])]
    speed_colors = [np.array([245, 250, 254]), np.array([250, 254, 250])]
    multipliers = [85, 35]
    multipliers = [150, 150]

    # set distance parameters
    close_to_shelter_distance = 40
    close_to_shelter_angle = 60

    # create local variables for the current epoch
    goal_speeds, absolute_speeds, shelter_angles, angular_speed, distance_from_shelter, distance_from_subgoal, within_subgoal_bound = \
        create_local_variables(coordinates, stim_frame, previous_stim_frame, skip_frames)

    # do convolutions to get current, future, far future, and past speeds w.r.t the shelter
    current_speed = convolve(goal_speeds, 24, -1, time = 'current')
    past_speed = convolve(goal_speeds, 45, -1, time = 'past')
    future_speed = convolve(goal_speeds, 60, -1, time='future')
    far_future_speed = convolve(goal_speeds, 60, -1, time = 'far future', time_chase = 20)

    # is the mouse close enough to the shelter
    minimum_distance = 400
    close_enough_to_shelter = convolve(distance_from_shelter < minimum_distance, 60, +1, time = 'future')
    angle_thresholded = np.array(within_subgoal_bound) + threshold(abs(shelter_angles), close_to_shelter_angle, '<')
    distance_thresholded = threshold(distance_from_shelter, close_to_shelter_distance)

    # loop across fast and slow homings
    for speed_setting in [True, False]:

        # use higher speed setting to make faster homings darker
        low_speed, medium_speed, high_speed = speeds[speed_setting][0], speeds[speed_setting][1], speeds[speed_setting][2]

        # threshold the convolved speeds to determine which frames to draw
        current_speed_thrsh = threshold(current_speed, high_speed)
        future_speed_thrsh  = threshold(future_speed, high_speed) * threshold(current_speed, medium_speed)
        far_future_speed_thrsh = threshold(far_future_speed, high_speed) * threshold(current_speed, medium_speed)
        past_speed_thrsh = threshold(past_speed, high_speed) * threshold(current_speed, medium_speed)
        stimulus_thresholded = threshold(frame_nums, stim_frame-1) * threshold(absolute_speeds, low_speed / 2)

        # combine speed thresholds into one
        combined_speed_thresholds = (current_speed_thrsh + future_speed_thrsh + far_future_speed_thrsh + past_speed_thrsh + stimulus_thresholded)

        # combine all thresholds into one
        thresholds_passed_first_pass = distance_thresholded * angle_thresholded * close_enough_to_shelter * combined_speed_thresholds

        # and smooth it *out*
        smooth_duration = 40
        thresholds_passed_first_pass = convolve(thresholds_passed_first_pass, smooth_duration, +1, time = 'current').astype(bool)

        # finally, add a minimum duration threshold
        minimum_distance = -.5 + .25 * speed_setting # this will be problematic for other arenas
        minimum_duration = 30 + smooth_duration #- 15 * speed_setting
        thresholds_passed_first_pass, start_idx = minimum_duration_threshold(thresholds_passed_first_pass* (1 - thresholds_passed),
                                                                             minimum_distance, minimum_duration, distance_from_subgoal)

        # get the index when adequately long locomotor bouts pass the threshold
        thresholds_passed = thresholds_passed_first_pass + (frame_nums==stim_frame)
        thresholds_passed_idx = np.where(thresholds_passed)[0]

        # loop over each frame that passed the threshold
        for idx in thresholds_passed_idx:

            # get frame number
            frame_num = frame_nums[idx]

            # get duration of homing
            if start_idx[idx]:
                duration = start_idx[idx]
                prior_exploration_arena = exploration_arena.copy()
            #     reset_timer = 0
            #     pure_color = False
            #
            # # reset mask every 10 frames
            # reset_timer += 1
            # if reset_timer == 60:
            #     color = exploration_arena[coordinates['center_body_location'][1][frame_num - 1].astype(np.uint16), coordinates['center_body_location'][0][frame_num - 1].astype(np.uint16)]
            #     pure_color = True
            #     model_mouse_mask_initial = model_mouse_mask_initial * 0
            #

            # draw model mouse
            back_butt_dist = 12 #+ speed_setting * 2
            model_mouse_mask, model_mouse_mask_initial = draw_mouse(model_mouse_mask_initial, coordinates, frame_num, back_butt_dist, start_idx[idx], stim_frame, stimulus_contour_retrieved)

            # determine color and darkness
            color_multiplier, save_color_multiplier, too_dark = get_color_settings(frame_num, stim_frame, speed_setting, speed_colors, multipliers,
                                                                                   exploration_arena, model_mouse_mask, duration)
            if too_dark: continue

            # on the stimulus onset, get the contours of the mouse body
            if frame_num >= stim_frame and not stimulus_contour_retrieved:
                save_exploration_arena, stimulus_contour_retrieved, contours = stimulus_onset(stimulus_contour_retrieved, model_mouse_mask, exploration_arena)
                continue

            # apply color to arena image
            # exploration_arena[model_mouse_mask.astype(bool)] = exploration_arena[model_mouse_mask.astype(bool)] * color_multiplier

            # exploration_arena[model_mouse_mask.astype(bool)] = (( 80 * exploration_arena[model_mouse_mask.astype(bool)].astype(np.uint16) +
            #                                                       1 * np.array(speed_colors[speed_setting]) ) / 81).astype(np.uint8)
            # #
            # exploration_arena[model_mouse_mask.astype(bool)] = (( 119 * exploration_arena[model_mouse_mask.astype(bool)].astype(np.uint16) +
            #                                                       1 * prior_exploration_arena[model_mouse_mask.astype(bool)].astype(np.uint16)) / 120).astype(np.uint8)

            exploration_arena[model_mouse_mask.astype(bool)] = (( 399 * exploration_arena[model_mouse_mask.astype(bool)].astype(np.uint16) * color_multiplier +
                                                                  1 * prior_exploration_arena[model_mouse_mask.astype(bool)].astype(np.uint16)) / 300).astype(np.uint8)

            # apply color to this trial's image
            if frame_num >= stim_frame or not speed_setting:
                save_exploration_arena[model_mouse_mask.astype(bool)] = save_exploration_arena[model_mouse_mask.astype(bool)] * save_color_multiplier

                if frame_num < stim_frame:
                    save_exploration_arena[model_mouse_mask.astype(bool)] = ((199 * save_exploration_arena[model_mouse_mask.astype(bool)].astype(np.uint16) +
                                                                         1 * prior_exploration_arena[model_mouse_mask.astype(bool)].astype(np.uint16)) / 200).astype(np.uint8)

            # display image
            # exploration_arena[exploration_arena < ]
            cv2.imshow(savepath +'homings', exploration_arena)

            # press q to quit
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    # apply the contours and border to the image and save the image
    try:
        # save_exploration_arena = cv2.drawContours(save_exploration_arena, contours, 0, (150, 150, 150), -1) #(90, 0, 200), -1) # 164, 181, 124
        # save_exploration_arena = cv2.drawContours(save_exploration_arena, contours, 0, (0,0,0), 2) #(90, 0, 200), 1)
        session_trials_plot_background[border_size:, 0:-border_size] = save_exploration_arena
        scipy.misc.imsave(os.path.join(savepath, videoname + '_spont_homings.tif'), cv2.cvtColor(session_trials_plot_background, cv2.COLOR_BGR2RGB))
    except:
        print('repeat stimulus trial')



    return exploration_arena


#
# def goalness():
#     '''
#     compute and display GOALNESS DURING EXPLORATION
#     go through each frame, adding the mouse silhouette
#     '''
#
#     scale = int(frame.shape[0] /10)
#     goal_arena, _, _ = model_arena(frame.shape[0:2], trial_type, False, False, obstacle_type)
#     speed_map = np.zeros((scale, scale))
#     occ_map = np.zeros((scale, scale))
#
#     goal_map = np.zeros((scale, scale))
#
#     # stim_erase_idx = np.arange(len(coordinates['center_location'][0][:stim_frame]))
#     # stim_erase_idx = [np.min(abs(x - stims)) for x in stim_erase_idx]
#     # stim_erase_idx = [x > 300 for x in stim_erase_idx]
#
#     # filter_sequence = np.concatenate( (np.ones(15)*-np.percentile(coordinates['speed'],99.5), np.zeros(10)) )
#     filter_sequence = np.ones(20) * -np.percentile(coordinates['speed'], 99.5)
#     print(colored(' Calculating goalness...', 'green'))
#     for x_loc in tqdm(range(occ_map.shape[0])):
#         for y_loc in range(occ_map.shape[1]):
#             curr_dist = np.sqrt((coordinates['center_location'][0][:stim_frame] - ((720 / scale) * (x_loc + 1 / 2))) ** 2 +
#                                 (coordinates['center_location'][1][:stim_frame] - ((720 / scale) * (y_loc + 1 / 2))) ** 2)
#             occ_map[x_loc, y_loc] = np.mean(curr_dist < (2 * 720 / scale))
#             curr_speed = np.concatenate(([0], np.diff(curr_dist))) # * np.array(stim_erase_idx)  # * (coordinates['center_location'][1] < 360) #
#             speed_map[x_loc, y_loc] = abs(np.mean(curr_speed < -np.percentile(coordinates['speed'], 99.5)))
#
#             goal_map[x_loc, y_loc] = np.percentile(np.concatenate((np.zeros(len(filter_sequence) - 1),
#                                                                    np.convolve(curr_speed, filter_sequence, mode='valid'))) * (curr_dist < 60), 99.8)  # 98
#
#     goal_map_plot = goal_map.T * (occ_map.T > 0)
#
#     goal_image = goal_map_plot.copy()
#
#     goal_image = goal_image * 255 / np.percentile(goal_map_plot, 99)
#     goal_threshold = int(np.percentile(goal_map_plot, 90) * 255 / np.percentile(goal_map_plot, 99))
#
#     goal_image[goal_image > 255] = 255
#     goal_image = cv2.resize(goal_image.astype(np.uint8), frame.shape[0:2])
#
#     goal_image[goal_image <= int(goal_threshold * 1 / 5) * (goal_image > 1)] = int(goal_threshold * 1 / 10)
#     goal_image[(goal_image <= goal_threshold * 2 / 5) * (goal_image > int(goal_threshold * 1 / 5))] = int(goal_threshold * 2 / 10)
#     goal_image[(goal_image <= goal_threshold * 3 / 5) * (goal_image > int(goal_threshold * 2 / 5))] = int(goal_threshold * 3 / 10)
#     goal_image[(goal_image <= goal_threshold * 4 / 5) * (goal_image > int(goal_threshold * 3 / 5))] = int(goal_threshold * 4 / 10)
#     goal_image[(goal_image <= goal_threshold) * (goal_image > int(goal_threshold * 4 / 5))] = int(goal_threshold * 6 / 10)
#     goal_image[(goal_image < 255) * (goal_image > goal_threshold)] = int(goal_threshold)
#
#     # goal_image[(arena_fresh[:,:,0] > 0) * (goal_image == 0)] = int(goal_threshold * 1 / 5)
#     goal_image[(arena_fresh[:, :, 0] < 100)] = 0
#
#     goal_image = cv2.copyMakeBorder(goal_image, border_size, 0, 0, 0, cv2.BORDER_CONSTANT, value=0)
#     textsize = cv2.getTextSize(videoname, 0, .55, 1)[0]
#     textX = int((width - textsize[0]) / 2)
#     cv2.putText(goal_image, videoname, (textX, int(border_size * 3 / 4)), 0, .55, (255, 255, 255), thickness=1)
#     scipy.misc.imsave(os.path.join(savepath, videoname + '_goalness.tif'), goal_image)
#
#     cv2.imshow('goal', goal_image)
#     cv2.waitKey(1)




#
#
# def planning(savepath, videoname, coordinates, height, width, trial_type, obstacle_type, previous_stim_frame, stim_frame):
#     '''
#     compute and display PLANNESS DURING EXPLORATION
#     go through each frame, adding the mouse silhouette
#     '''
#
#     # get model arena and downsample x10
#     downsample = 20
#     scale = int(height / downsample)
#     radius = np.sqrt(2*downsample**2)
#
#     # determine when the mouse is in the shelter
#     in_shelter = coordinates['distance_from_shelter'][:stim_frame] < 100
#     x_location = coordinates['center_location'][0][:stim_frame]
#     y_location = coordinates['center_location'][1][:stim_frame]
#
#     # determine when the mouse isn't moving toward the shelter
#     speed = coordinates['speed_toward_shelter'][:stim_frame]
#     # high_speed = np.percentile(speed, 99)*2
#     slow_speed = abs(speed) < .5
#
#     # determine when the mouse is moving toward the shelter
#     filter = np.ones(15)
#     future_speed = np.concatenate((np.convolve(speed, filter, mode='valid'), np.zeros(len(filter) - 1))) / len(filter)
#     will_move_toward_shelter = future_speed < -.5
#
#
#     # determine how long from each frame to the next frame in the shelter
#     time_to_shelter = []; groups = []
#     for k, g in itertools.groupby(in_shelter):
#         groups.append(list(g))
#         group_length = len(groups[len(groups) - 1]);
#         # if in the shelter, set value to zero
#         if k:
#             time_to_shelter = time_to_shelter + [255 for x in range(group_length)]
#         # if not in shelter, set value to timesteps to shelter
#         else:
#             current_time_to_shelter = [x for x in range(1, group_length+1)]
#             time_to_shelter = time_to_shelter + current_time_to_shelter[::-1]
#     time_to_shelter = np.array(time_to_shelter)
#
#     # initialize planning maps
#     plan_map = np.zeros((scale, scale))
#
#     # loop over each location on a grid
#     for x_loc in tqdm(range(plan_map.shape[0])):
#         for y_loc in range(plan_map.shape[1]):
#             # get indices when mouse is in current square
#             within_square = ( abs(x_location - ((width  / scale) * (x_loc + 1 / 2)) ) <= downsample/2 ) * \
#                             ( abs(y_location - ((height / scale) * (y_loc + 1 / 2))) <= downsample/2 )
#
#             # if there is any occupancy (during slow movement and future movement toward shelter)
#             if np.sum(within_square * slow_speed * will_move_toward_shelter):
#                 plan_map[y_loc, x_loc] = np.percentile(time_to_shelter[within_square * slow_speed * will_move_toward_shelter], 1) #np.min(time_to_shelter[within_square * slow_speed])
#             else:
#                 plan_map[y_loc, x_loc] = 255
#
#     # copy the plan map for plotting and reformate to be uint8
#     plan_map_plot = plan_map.copy()
#     plan_map_plot[plan_map_plot>=255] = 255
#     plan_map_plot = 255 - plan_map_plot.astype(np.uint8)
#
#     # upsample plot and then apply median filter
#     plan_map_plot = cv2.resize(plan_map_plot, (width, height), interpolation=cv2.INTER_CUBIC)
#     plan_map_plot = scipy.signal.medfilt2d(plan_map_plot, kernel_size=71)
#
#     # show plot of plans (white on black)
#     cv2.imshow('plans', plan_map_plot)
#
#     # draw arena
#     arena, _, _ = model_arena((height, width), trial_type, False, obstacle_type)
#     arena_color = cv2.cvtColor(arena, cv2.COLOR_GRAY2RGB)
#     arena_color_copy = arena_color.copy()
#
#     # convert plan map to color
#     plan_map_color = cv2.cvtColor(plan_map_plot, cv2.COLOR_GRAY2RGB)
#
#     # get the total intensity of pixels on this plot
#     total_plans = np.sum(plan_map_plot)
#
#     # get each blob of pixels
#     _, contours, _ = cv2.findContours(plan_map_plot, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
#
#     # initialize mask
#     blank_image = np.zeros(arena.shape)
#
#     # color in each blob from the plan map onto the arena plot
#     for c in range(len(contours)):
#         # draw contours on the blank mask
#         contour_mask = cv2.drawContours(blank_image.copy(), contours, c, color=(1, 1, 1), thickness=cv2.FILLED)
#
#         # calculate the importance of this particular blob
#         plans_in_curr_contour = np.sum(plan_map_plot[contour_mask.astype(bool)]) / total_plans
#
#         # for planning points accounting for at least 5% of planning utility, draw them in on the arena plot
#         if plans_in_curr_contour > .05:
#             arena_color[contour_mask.astype(bool)] = (255 - plan_map_color[contour_mask.astype(bool)]* [1, plans_in_curr_contour, 1])
#
#     # or color in all blobs at once
#     arena_color[plan_map_plot.astype(bool)] = plan_map_color[plan_map_plot.astype(bool)]
#
#     # draw the shelter and obstacle, in case they were drawn over
#     arena_color[arena<255] = arena_color_copy[arena<255]
#
#     # show the arena
#     cv2.imshow('arena', arena_color)
#     cv2.waitKey(1)
#
#     # save the image
#     scipy.misc.imsave(os.path.join(savepath, videoname + '_planning.tif'), cv2.cvtColor(arena_color, cv2.COLOR_BGR2RGB))


    filter_sequence = np.ones(20) * -np.percentile(coordinates['speed'], 99.5)
    print(colored(' Calculating planness...', 'green'))
    speed_toward_shelter = np.convolve(coordinates['speed_toward_shelter'][:stim_frame], filter_sequence, mode='valid')
    distance_from_shelter = coordinates['distance_from_shelter'][:stim_frame]
    # arrival_in_shelter = coordinates['distance_from_shelter'][:stim_frame] < 100
    # future_arrival_in_shelter = np.concatenate( (arrival_in_shelter[:-30], np.zeros(30) ) )
    for x_loc in tqdm(range(occ_map.shape[0])):
        for y_loc in range(occ_map.shape[1]):
            curr_dist = np.sqrt((coordinates['center_location'][0][:stim_frame] - ((720 / scale) * (x_loc + 1 / 2))) ** 2 +
                                (coordinates['center_location'][1][:stim_frame] - ((720 / scale) * (y_loc + 1 / 2))) ** 2)
            occ_map[x_loc, y_loc] = np.mean(curr_dist < (2 * 720 / scale))
            # curr_speed = np.concatenate(([0], np.diff(curr_dist)))  # * np.array(stim_erase_idx)  # * (coordinates['center_location'][1] < 360) #
            # speed_map[x_loc, y_loc] = abs(np.mean(curr_speed < -np.percentile(coordinates['speed'], 99.5)))

            plan_map[x_loc, y_loc] = np.percentile(
                np.concatenate((speed_toward_shelter, np.zeros(len(filter_sequence) - 1))) * (curr_dist < 50) * (distance_from_shelter > 175), 99.2)  # 98

    plan_map_plot = plan_map.T * (occ_map.T > 0)

    plan_image = plan_map_plot.copy()

    plan_image = plan_image * 255 / np.percentile(plan_map_plot, 99.9)
    try:
        plan_threshold = int(np.percentile(plan_map_plot, 99) * 255 / np.percentile(plan_map_plot, 99.9))
    except:
        plan_threshold = 200

    plan_image[plan_image > 255] = 255
    plan_image = cv2.resize(plan_image.astype(np.uint8), frame.shape[0:2])

    plan_image[plan_image <= int(plan_threshold * 1 / 5) * (plan_image > 1)] = int(plan_threshold * 1 / 5)
    plan_image[(plan_image <= plan_threshold * 2 / 5) * (plan_image > int(plan_threshold * 1 / 5))] = int(plan_threshold * 3 / 5)
    plan_image[(plan_image <= plan_threshold * 3 / 5) * (plan_image > int(plan_threshold * 2 / 5))] = int(plan_threshold * 3 / 5)
    plan_image[(plan_image <= plan_threshold * 4 / 5) * (plan_image > int(plan_threshold * 3 / 5))] = int(plan_threshold * 4 / 5)
    plan_image[(plan_image <= plan_threshold) * (plan_image > int(plan_threshold * 4 / 5))] = plan_threshold
    plan_image[(plan_image < 255) * (plan_image > plan_threshold)] = int((plan_threshold + 255) / 2)

    # plan_image[(arena_fresh[:,:,0] > 0) * (plan_image == 0)] = int(plan_threshold * 3 / 10)
    plan_image[(arena_fresh[:, :, 0] < 100)] = 0

    plan_image = cv2.copyMakeBorder(plan_image, border_size, 0, 0, 0, cv2.BORDER_CONSTANT, value=0)
    textsize = cv2.getTextSize(videoname, 0, .55, 1)[0]
    textX = int((width - textsize[0]) / 2)
    cv2.putText(plan_image, videoname, (textX, int(border_size * 3 / 4)), 0, .55, (255, 255, 255), thickness=1)
    scipy.misc.imsave(os.path.join(savepath, videoname + '_planness.tif'), plan_image)


                # model_flight_image = ((model_flight_image.astype(float)*3 + arena_fresh.astype(float)*1 ) / 4).astype(np.uint8)
                # session_trials_plot = ((session_trials_plot.astype(float) * 1 + initial_session_trials_plot.astype(float) * 1) / 2).astype(np.uint8)   

             # cv2.circle(session_trials_plot_background, tuple(coordinates['nose'][:,frame_num-1].astype(np.uint16)), 2, (0,0,0), -1)
                # cv2.circle(session_trials_plot_background, tuple(coordinates['L eye'][:, frame_num - 1].astype(np.uint16)), 2, (0,0,0), -1)
                # cv2.circle(session_trials_plot_background, tuple(coordinates['R eye'][:, frame_num - 1].astype(np.uint16)), 2, (0,0,0), -1)
                # cv2.circle(session_trials_plot_background, tuple(coordinates['L ear'][:, frame_num - 1].astype(np.uint16)), 2, (0,0,0), -1)
                # cv2.circle(session_trials_plot_background, tuple(coordinates['neck'][:, frame_num - 1].astype(np.uint16)), 2, (0,0,0), -1)
                # cv2.circle(session_trials_plot_background, tuple(coordinates['R ear'][:, frame_num - 1].astype(np.uint16)), 2, (0,0,0), -1)


# if vid_num:
#     if not 'Arena Transformation 2' in self.session['Metadata'].videodata[0]:
#         self.session['Metadata'].videodata[0]['Arena Transformation 2'] = []
#         self.session['Metadata'].videodata[0]['Arena Transformation 2'] = register_arena(
#          self.session['Metadata'].videodata[0]['Background'], fisheye_map_location, self.x_offset, self.y_offset, self.obstacle_type)
#     self.registration = self.session['Metadata'].videodata[0]['Arena Transformation 2']
# if not vid_num:
#   self.videoname = '{}_{}_{}-{} ({}\')'.format(self.session['Metadata'].experiment,
#                                                                      self.session['Metadata'].mouse_id,
#                                                                      stim_type, trial_num + 1 + vid_1_trials, round((stim_frame + vid_1_frames) / self.fps / 60))
#
# vid_1_frames = end_frame
# vid_1_trials = trial_num



# def find_raw_video(video_path):
#     vid = cv2.VideoCapture(video_path)
#     ret, frame = vid.read()
#     vid.release()
#     print(colored('Tracking the whole session from ' + video_path, 'green'))
#
#     return video_path, frame

    # video_clip_EXPLORE = cv2.VideoWriter(os.path.join(savepath, videoname + '_EXPLORE.avi'), fourcc,
    #                                  200, (width, height), True)
    # in_color = np.array([122, 222, 122])
    # out_color = np.array([122, 122, 222])

    # explore_in_color = 1 - ( 1 - in_color / [255, 255, 255] ) / ( np.mean( 1 - in_color / [255, 255, 255] ) / .08)
    # explore_out_color = 1 - ( 1 - out_color / [255, 255, 255] ) / ( np.mean( 1 - out_color / [255, 255, 255] ) / .08)

# AWAY FROM SHELTER
# if speed_toward_shelter > 0:
#     fast_color = np.array([152, 152, 222]) # red
#     slow_color = np.array([155, 225, 245]) # brown-yellow
#     slow_color = np.array([224, 245, 245])  # gray yellow
#     multiplier = .02
#     if speed > 10:
#         speed_color = fast_color
#     else:
#         speed_color = (speed * fast_color + (10 - speed) * slow_color) / 10
#
#     speed_color = 1 - (1 - speed_color / [255, 255, 255]) / (np.mean(1 - speed_color / [255, 255, 255]) / (.1 * speed * multiplier))
#
#     exploration_arena_both[model_mouse_mask.astype(bool)] = exploration_arena_both[model_mouse_mask.astype(bool)] * speed_color

########################################################################################################################


# # =================================================================================
# #              GENERATE PERI-STIMULUS VIDEO CLIPS and FLIGHT IMAGE
# # =================================================================================
# def peri_stimulus_video_clip(vidpath = '', videoname = '', savepath = '', start_frame=0., end_frame=100., stim_frame = 0,
#                    registration = 0, fps=False, save_clip = False, display_clip = False, counter = True, make_flight_image = True):
#     # GET BEAHVIOUR VIDEO - ######################################
#     vid = cv2.VideoCapture(vidpath)
#     if not fps: fps = vid.get(cv2.CAP_PROP_FPS)
#     width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))
#     height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
#
#     # SETUP VIDEO CLIP SAVING - ######################################
#     # file_already_exists = os.path.isfile(os.path.join(savepath,videoname+'.avi'))
#     fourcc = cv2.VideoWriter_fourcc(*"XVID")  # LJPG for lossless, XVID for compressed
#     border_size = 20
#     if save_clip:
#         if not os.path.isdir(savepath):
#             os.makedirs(savepath)
#         video_clip = cv2.VideoWriter(os.path.join(savepath,videoname+'.avi'), fourcc, fps, (width+2*border_size*counter, height+2*border_size*counter), counter)
#     vid.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
#
#     pre_stim_color = [255, 120, 120]
#     post_stim_color = [120, 120, 255]
#
#     if registration[3]: # setup fisheye correction
#         maps = np.load(registration[3])
#         map1 = maps[:, :, 0:2]
#         map2 = maps[:, :, 2] * 0
#     else:
#         print(colored('Fisheye correction unavailable', 'green'))
#     # RUN SAVING AND ANALYSIS OVER EACH FRAME - ######################################
#     while True: #and not file_already_exists:
#         ret, frame = vid.read()  # get the frame
#         if ret:
#             frame_num = vid.get(cv2.CAP_PROP_POS_FRAMES)
#             if [registration]:
#                 # load the fisheye correction
#                 frame_register = frame[:, :, 0]
#                 if registration[3]:
#                     frame_register = cv2.copyMakeBorder(frame_register, y_offset, int((map1.shape[0] - frame.shape[0]) - y_offset),
#                                                         x_offset, int((map1.shape[1] - frame.shape[1]) - x_offset), cv2.BORDER_CONSTANT, value=0)
#                     frame_register = cv2.remap(frame_register, map1, map2, interpolation=cv2.INTER_LINEAR,
#                                                 borderMode=cv2.BORDER_CONSTANT, borderValue=0)
#                     frame_register = frame_register[y_offset:-int((map1.shape[0] - frame.shape[0]) - y_offset),
#                                      x_offset:-int((map1.shape[1] - frame.shape[1]) - x_offset)]
#                 frame = cv2.cvtColor(cv2.warpAffine(frame_register, registration[0], frame.shape[0:2]),cv2.COLOR_GRAY2RGB)
#
#             # MAKE ESCAPE TRAJECTORY IMAGE - #######################################
#             if make_flight_image:
#                 # at stimulus onset, take this frame to lay all the superimposed mice on top of
#                 if frame_num == stim_frame:
#                     flight_image_by_distance = frame[:,:,0].copy()
#
#                 # in subsequent frames, see if frame is different enough from previous image to merit joining the image
#                 elif frame_num > stim_frame and (frame_num - stim_frame) < 30*10:
#                     # get the number of pixels that are darker than the flight image
#                     difference_from_previous_image = ((frame[:,:,0]+.001) / (flight_image_by_distance+.001))<.55 #.5 original parameter
#                     number_of_darker_pixels = np.sum(difference_from_previous_image)
#
#                     # if that number is high enough, add mouse to image
#                     if number_of_darker_pixels > 1050: # 850 original parameter
#                         # add mouse where pixels are darker
#                         flight_image_by_distance[difference_from_previous_image] = frame[difference_from_previous_image,0]
#
#             # SHOW BOUNDARY AND TIME COUNTER - #######################################
#             if counter and (display_clip or save_clip):
#                 # cv2.rectangle(frame, (0, height), (150, height - 60), (150,150,150), -1)
#                 if frame_num < stim_frame:
#                     cur_color = tuple([x * ((frame_num - start_frame) / (stim_frame - start_frame)) for x in pre_stim_color])
#                     sign = ''
#                 else:
#                     cur_color = tuple([x * (1 - (frame_num - stim_frame) / (end_frame-stim_frame))  for x in post_stim_color])
#                     sign = '+'
#
#                 # border and colored rectangle around frame
#                 frame = cv2.copyMakeBorder(frame, border_size, border_size, border_size, border_size,cv2.BORDER_CONSTANT, value=cur_color)
#
#                 # report video details
#                 cv2.putText(frame, videoname, (20, 40), 0, .55, (180, 180, 180), thickness=1)
#
#                 # report time relative to stimulus onset
#                 frame_time = (frame_num - stim_frame) / fps
#                 frame_time = str(round(.1*round(frame_time/.1), 1))+ '0'*(abs(frame_time)<10)
#                 cv2.putText(frame, sign + str(frame_time) + 's', (width-110, height+10), 0, 1,(180,180,180), thickness=2)
#
#             else:
#                 frame = frame[:,:,0] # or use 2D grayscale image instead
#
#             # SHOW AND SAVE FRAME - #######################################
#             if display_clip:
#                 cv2.imshow('Trial Clip', frame)
#             if save_clip:
#                 video_clip.write(frame)
#             if display_clip:
#                 if cv2.waitKey(1) & 0xFF == ord('q'):
#                     break
#             if frame_num >= end_frame:
#                 break
#         else:
#             print('Problem with movie playback')
#             cv2.waitKey(1000)
#             break
#
#     # wrap up
#     vid.release()
#     if make_flight_image:
#         flight_image_by_distance = cv2.copyMakeBorder(flight_image_by_distance, border_size, border_size, border_size, border_size, cv2.BORDER_CONSTANT, value=0)
#         cv2.putText(flight_image_by_distance, videoname, (border_size, border_size-5), 0, .55, (180, 180, 180), thickness=1)
#         cv2.imshow('Flight image', flight_image_by_distance)
#         cv2.waitKey(10)
#         scipy.misc.imsave(os.path.join(savepath, videoname + '.tif'), flight_image_by_distance)
#     if save_clip:
#         video_clip.release()
#     # cv2.destroyAllWindows()
#
